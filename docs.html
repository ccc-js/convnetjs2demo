
<!-- saved from url=(0059)https://cs.stanford.edu/people/karpathy/convnetjs/docs.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252"></head><body><div class="line-gutter-backdrop"></div><table><tbody><tr><td class="line-number" value="1"></td><td class="line-content"><span class="html-doctype">&lt;!DOCTYPE html&gt;</span></td></tr><tr><td class="line-number" value="2"></td><td class="line-content"><span class="html-tag">&lt;html&gt;</span></td></tr><tr><td class="line-number" value="3"></td><td class="line-content">  <span class="html-tag">&lt;head&gt;</span></td></tr><tr><td class="line-number" value="4"></td><td class="line-content">    <span class="html-tag">&lt;title&gt;</span>ConvNetJS: Deep Learning in your browser<span class="html-tag">&lt;/title&gt;</span></td></tr><tr><td class="line-number" value="5"></td><td class="line-content">    <span class="html-tag">&lt;link <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://cs.stanford.edu/people/karpathy/convnetjs/style.css" rel="noreferrer noopener">style.css</a>" <span class="html-attribute-name">rel</span>="<span class="html-attribute-value">stylesheet</span>"&gt;</span></td></tr><tr><td class="line-number" value="6"></td><td class="line-content">    <span class="html-tag">&lt;link <span class="html-attribute-name">href</span>='<a class="html-attribute-value html-resource-link" target="_blank" href="http://fonts.googleapis.com/css?family=Cabin" rel="noreferrer noopener">http://fonts.googleapis.com/css?family=Cabin</a>' <span class="html-attribute-name">rel</span>='<span class="html-attribute-value">stylesheet</span>' <span class="html-attribute-name">type</span>='<span class="html-attribute-value">text/css</span>'&gt;</span></td></tr><tr><td class="line-number" value="7"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="8"></td><td class="line-content">    <span class="html-tag">&lt;script&gt;</span></td></tr><tr><td class="line-number" value="9"></td><td class="line-content">      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){</td></tr><tr><td class="line-number" value="10"></td><td class="line-content">      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),</td></tr><tr><td class="line-number" value="11"></td><td class="line-content">      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)</td></tr><tr><td class="line-number" value="12"></td><td class="line-content">      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');</td></tr><tr><td class="line-number" value="13"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="14"></td><td class="line-content">      ga('create', 'UA-3698471-21', 'stanford.edu');</td></tr><tr><td class="line-number" value="15"></td><td class="line-content">      ga('send', 'pageview');</td></tr><tr><td class="line-number" value="16"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="17"></td><td class="line-content">    <span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="18"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="19"></td><td class="line-content">    <span class="html-comment">&lt;!-- JS syntax highlighting --&gt;</span></td></tr><tr><td class="line-number" value="20"></td><td class="line-content">    <span class="html-tag">&lt;script <span class="html-attribute-name">type</span>="<span class="html-attribute-value">text/javascript</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://cs.stanford.edu/people/karpathy/convnetjs/syntaxhighlighter_3.0.83/scripts/shCore.js" rel="noreferrer noopener">syntaxhighlighter_3.0.83/scripts/shCore.js</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="21"></td><td class="line-content">    <span class="html-tag">&lt;script <span class="html-attribute-name">type</span>="<span class="html-attribute-value">text/javascript</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://cs.stanford.edu/people/karpathy/convnetjs/syntaxhighlighter_3.0.83/scripts/shBrushJScript.js" rel="noreferrer noopener">syntaxhighlighter_3.0.83/scripts/shBrushJScript.js</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="22"></td><td class="line-content">    <span class="html-tag">&lt;link <span class="html-attribute-name">type</span>="<span class="html-attribute-value">text/css</span>" <span class="html-attribute-name">rel</span>="<span class="html-attribute-value">stylesheet</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://cs.stanford.edu/people/karpathy/convnetjs/syntaxhighlighter_3.0.83/styles/shCoreDefault.css" rel="noreferrer noopener">syntaxhighlighter_3.0.83/styles/shCoreDefault.css</a>"/&gt;</span></td></tr><tr><td class="line-number" value="23"></td><td class="line-content">    <span class="html-tag">&lt;script <span class="html-attribute-name">type</span>="<span class="html-attribute-value">text/javascript</span>"&gt;</span>SyntaxHighlighter.all();<span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="24"></td><td class="line-content">    <span class="html-tag">&lt;style&gt;</span></td></tr><tr><td class="line-number" value="25"></td><td class="line-content">    .syntaxhighlighter {</td></tr><tr><td class="line-number" value="26"></td><td class="line-content">      width: 100% !important;</td></tr><tr><td class="line-number" value="27"></td><td class="line-content">      margin: 1em 0 1em 0 !important;</td></tr><tr><td class="line-number" value="28"></td><td class="line-content">      position: relative !important;</td></tr><tr><td class="line-number" value="29"></td><td class="line-content">      overflow: hidden !important;</td></tr><tr><td class="line-number" value="30"></td><td class="line-content">      font-size: 14px !important; </td></tr><tr><td class="line-number" value="31"></td><td class="line-content">    }</td></tr><tr><td class="line-number" value="32"></td><td class="line-content">    <span class="html-tag">&lt;/style&gt;</span></td></tr><tr><td class="line-number" value="33"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="34"></td><td class="line-content">  <span class="html-tag">&lt;/head&gt;</span></td></tr><tr><td class="line-number" value="35"></td><td class="line-content">  <span class="html-tag">&lt;body&gt;</span></td></tr><tr><td class="line-number" value="36"></td><td class="line-content">    <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://github.com/karpathy/convnetjs" rel="noreferrer noopener">https://github.com/karpathy/convnetjs</a>"&gt;</span><span class="html-tag">&lt;img <span class="html-attribute-name">style</span>="<span class="html-attribute-value">position: absolute; top: 0; right: 0; border: 0;</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" rel="noreferrer noopener">https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png</a>" <span class="html-attribute-name">alt</span>="<span class="html-attribute-value">Fork me on GitHub</span>"&gt;</span><span class="html-tag">&lt;/a&gt;</span></td></tr><tr><td class="line-number" value="37"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="38"></td><td class="line-content">    <span class="html-tag">&lt;div <span class="html-attribute-name">id</span>="<span class="html-attribute-value">wrap</span>"&gt;</span></td></tr><tr><td class="line-number" value="39"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="40"></td><td class="line-content">      <span class="html-tag">&lt;div <span class="html-attribute-name">id</span>="<span class="html-attribute-value">header</span>"&gt;</span></td></tr><tr><td class="line-number" value="41"></td><td class="line-content">        <span class="html-tag">&lt;img <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://cs.stanford.edu/people/karpathy/convnetjs/logo.png" rel="noreferrer noopener">logo.png</a>" <span class="html-attribute-name">height</span>="<span class="html-attribute-value">70px</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">float:left;</span>"&gt;</span></td></tr><tr><td class="line-number" value="42"></td><td class="line-content">        <span class="html-tag">&lt;h1&gt;</span>ConvNetJS<span class="html-tag">&lt;/h1&gt;</span></td></tr><tr><td class="line-number" value="43"></td><td class="line-content">        <span class="html-tag">&lt;h2&gt;</span>Deep Learning in your browser<span class="html-tag">&lt;/h2&gt;</span></td></tr><tr><td class="line-number" value="44"></td><td class="line-content">      <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="45"></td><td class="line-content">      <span class="html-tag">&lt;div <span class="html-attribute-name">id</span>="<span class="html-attribute-value">menu</span>"&gt;</span></td></tr><tr><td class="line-number" value="46"></td><td class="line-content">        <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://cs.stanford.edu/people/karpathy/convnetjs/index.html" rel="noreferrer noopener">index.html</a>"&gt;</span><span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">menuit</span>"&gt;</span>Intro<span class="html-tag">&lt;/div&gt;</span><span class="html-tag">&lt;/a&gt;</span></td></tr><tr><td class="line-number" value="47"></td><td class="line-content">        <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://cs.stanford.edu/people/karpathy/convnetjs/intro.html" rel="noreferrer noopener">intro.html</a>"&gt;</span><span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">menuit</span>"&gt;</span>Deep Learning Resources<span class="html-tag">&lt;/div&gt;</span><span class="html-tag">&lt;/a&gt;</span></td></tr><tr><td class="line-number" value="48"></td><td class="line-content">        <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://cs.stanford.edu/people/karpathy/convnetjs/started.html" rel="noreferrer noopener">started.html</a>"&gt;</span><span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">menuit</span>"&gt;</span>Getting Started<span class="html-tag">&lt;/div&gt;</span><span class="html-tag">&lt;/a&gt;</span></td></tr><tr><td class="line-number" value="49"></td><td class="line-content">        <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://cs.stanford.edu/people/karpathy/convnetjs/docs.html" rel="noreferrer noopener">docs.html</a>"&gt;</span><span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">menuit mactive</span>"&gt;</span>Documentation<span class="html-tag">&lt;/div&gt;</span><span class="html-tag">&lt;/a&gt;</span></td></tr><tr><td class="line-number" value="50"></td><td class="line-content">      <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="51"></td><td class="line-content">      </td></tr><tr><td class="line-number" value="52"></td><td class="line-content">      <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">sec</span>"&gt;</span></td></tr><tr><td class="line-number" value="53"></td><td class="line-content">        <span class="html-tag">&lt;h3&gt;</span>Vols<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="54"></td><td class="line-content">        The entire library is based around transforming 3-dimensional volumes of numbers. These volumes are stored in the <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://github.com/karpathy/convnetjs/blob/master/src/convnet_vol.js" rel="noreferrer noopener">https://github.com/karpathy/convnetjs/blob/master/src/convnet_vol.js</a>"&gt;</span>Vol class<span class="html-tag">&lt;/a&gt;</span>, which is at the heart of the library. The Vol class is a wrapper around:</td></tr><tr><td class="line-number" value="55"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="56"></td><td class="line-content">        <span class="html-tag">&lt;ul&gt;</span> </td></tr><tr><td class="line-number" value="57"></td><td class="line-content">          <span class="html-tag">&lt;li&gt;</span>a 1-dimensional list of numbers (the activations, in field .w)<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="58"></td><td class="line-content">          <span class="html-tag">&lt;li&gt;</span>their gradients (field .dw)<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="59"></td><td class="line-content">          <span class="html-tag">&lt;li&gt;</span>and lastly contains three dimensions (fields .sx, .sy, .depth).<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="60"></td><td class="line-content">        <span class="html-tag">&lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="61"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="62"></td><td class="line-content">         Here are some examples:</td></tr><tr><td class="line-number" value="63"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="64"></td><td class="line-content"><span class="html-tag">&lt;pre <span class="html-attribute-name">class</span>="<span class="html-attribute-value">brush: js; toolbar: false;</span>"&gt;</span></td></tr><tr><td class="line-number" value="65"></td><td class="line-content">// create a Vol of size 32x32x3, and filled with random numbers</td></tr><tr><td class="line-number" value="66"></td><td class="line-content">var v = new convnetjs.Vol(32, 32, 3);</td></tr><tr><td class="line-number" value="67"></td><td class="line-content">var v = new convnetjs.Vol(32, 32, 3, 0.0); // same volume but init with zeros</td></tr><tr><td class="line-number" value="68"></td><td class="line-content">var v = new convnetjs.Vol(1, 1, 3); // a 1x1x3 Vol with random numbers</td></tr><tr><td class="line-number" value="69"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="70"></td><td class="line-content">// you can also initialize with a specific list. E.g. create a 1x1x3 Vol:</td></tr><tr><td class="line-number" value="71"></td><td class="line-content">var v = new convnetjs.Vol([1.2, 3.5, 3.6]);</td></tr><tr><td class="line-number" value="72"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="73"></td><td class="line-content">// the Vol is a wrapper around two lists: .w and .dw, which both have </td></tr><tr><td class="line-number" value="74"></td><td class="line-content">// sx * sy * depth number of elements. E.g:</td></tr><tr><td class="line-number" value="75"></td><td class="line-content">v.w[0] // contains 1.2</td></tr><tr><td class="line-number" value="76"></td><td class="line-content">v.dw[0] // contains 0, because gradients are initialized with zeros</td></tr><tr><td class="line-number" value="77"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="78"></td><td class="line-content">// you can also access the 3-D Vols with getters and setters</td></tr><tr><td class="line-number" value="79"></td><td class="line-content">// but these are subject to function call overhead</td></tr><tr><td class="line-number" value="80"></td><td class="line-content">var vol3d = new convnetjs.Vol(10, 10, 5);</td></tr><tr><td class="line-number" value="81"></td><td class="line-content">vol3d.set(2,0,1,5.0); // set coordinate (2,0,1) to 5.0</td></tr><tr><td class="line-number" value="82"></td><td class="line-content">vol3d.get(2,0,1) // returns 5.0</td></tr><tr><td class="line-number" value="83"></td><td class="line-content"><span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="84"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="85"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="86"></td><td class="line-content">      <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="87"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="88"></td><td class="line-content">      <span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="89"></td><td class="line-content">        <span class="html-tag">&lt;h3&gt;</span>Net<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="90"></td><td class="line-content">        <span class="html-tag">&lt;p&gt;</span></td></tr><tr><td class="line-number" value="91"></td><td class="line-content">          A <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://github.com/karpathy/convnetjs/blob/master/src/convnet_net.js" rel="noreferrer noopener">https://github.com/karpathy/convnetjs/blob/master/src/convnet_net.js</a>"&gt;</span>Net<span class="html-tag">&lt;/a&gt;</span> is a very simple class that simply contains a list of Layers (discussed below). When an example (in form of a Vol) is passed through the Net, the Net simply iterates through all of its layers and propagates the example through each one in turn, and returns the result of the last layer. Similarly, during backpropagation the Net calls the backward() function of each layer in turn to compute the gradient.</td></tr><tr><td class="line-number" value="92"></td><td class="line-content">        <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="93"></td><td class="line-content">      <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="94"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="95"></td><td class="line-content">      <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">sec</span>"&gt;</span></td></tr><tr><td class="line-number" value="96"></td><td class="line-content">        <span class="html-tag">&lt;h3&gt;</span>Layers<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="97"></td><td class="line-content">        <span class="html-tag">&lt;p&gt;</span></td></tr><tr><td class="line-number" value="98"></td><td class="line-content">        As mentioned, every Network is just a linear list of layers. Your first layer must be 'input' (in which you declare sizes of your input), your last layer must be a loss layer ('softmax' or 'svm' for classification, or 'regression' for regression). Every layer takes an input Vol and produces a new output Vol, which is why I prefer to refer to them as transformers.</td></tr><tr><td class="line-number" value="99"></td><td class="line-content">        <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="100"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="101"></td><td class="line-content">        <span class="html-tag">&lt;p&gt;</span></td></tr><tr><td class="line-number" value="102"></td><td class="line-content">        Before going into details of the types of available layers, lets look at an example at this point that ties these concepts together in a concrete form:</td></tr><tr><td class="line-number" value="103"></td><td class="line-content">        <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="104"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="105"></td><td class="line-content"><span class="html-tag">&lt;pre <span class="html-attribute-name">class</span>="<span class="html-attribute-value">brush: js; toolbar: false;</span>"&gt;</span></td></tr><tr><td class="line-number" value="106"></td><td class="line-content">var layer_defs = [];</td></tr><tr><td class="line-number" value="107"></td><td class="line-content">// minimal network: a simple binary SVM classifer in 2-dimensional space</td></tr><tr><td class="line-number" value="108"></td><td class="line-content">layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth:2});</td></tr><tr><td class="line-number" value="109"></td><td class="line-content">layer_defs.push({type:'svm', num_classes:2});</td></tr><tr><td class="line-number" value="110"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="111"></td><td class="line-content">// create a net</td></tr><tr><td class="line-number" value="112"></td><td class="line-content">var net = new convnetjs.Net();</td></tr><tr><td class="line-number" value="113"></td><td class="line-content">net.makeLayers(layer_defs);</td></tr><tr><td class="line-number" value="114"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="115"></td><td class="line-content">// create a 1x1x2 volume of input activations:</td></tr><tr><td class="line-number" value="116"></td><td class="line-content">var x = new convnetjs.Vol(1,1,2);</td></tr><tr><td class="line-number" value="117"></td><td class="line-content">x.w[0] = 0.5; // w is the field holding the actual data</td></tr><tr><td class="line-number" value="118"></td><td class="line-content">x.w[1] = -1.3;</td></tr><tr><td class="line-number" value="119"></td><td class="line-content">// a shortcut for the above is var x = new convnetjs.Vol([0.5, -1.3]);</td></tr><tr><td class="line-number" value="120"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="121"></td><td class="line-content">var scores = net.forward(x); // pass forward through network</td></tr><tr><td class="line-number" value="122"></td><td class="line-content">// scores is now a Vol() of output activations</td></tr><tr><td class="line-number" value="123"></td><td class="line-content">console.log('score for class 0 is assigned:'  + scores.w[0]);</td></tr><tr><td class="line-number" value="124"></td><td class="line-content">    <span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="125"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="126"></td><td class="line-content">        <span class="html-tag">&lt;h3&gt;</span>Generic Neural Network Layers<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="127"></td><td class="line-content">        <span class="html-tag">&lt;p&gt;</span>Lets now step through the details of the Layers:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="128"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="129"></td><td class="line-content">        <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">l</span>"&gt;</span></td></tr><tr><td class="line-number" value="130"></td><td class="line-content">          <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">lt</span>"&gt;</span>Input Layer<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="131"></td><td class="line-content">          <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">ld</span>"&gt;</span>A dummy layer that essentially declares the size of input volume and must be first layer in the network. Inputs other than real-valued numbers are currently not supported.<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="132"></td><td class="line-content">          <span class="html-tag">&lt;pre <span class="html-attribute-name">class</span>="<span class="html-attribute-value">brush: js; toolbar: false;</span>"&gt;</span></td></tr><tr><td class="line-number" value="133"></td><td class="line-content">          {type:'input', out_sx:1, out_sy:1, out_depth:20} // declares 20-dimensional input points</td></tr><tr><td class="line-number" value="134"></td><td class="line-content">          {type:'input', out_sx:24, out_sy:24, out_depth:3} // input is 24x24 RGB image</td></tr><tr><td class="line-number" value="135"></td><td class="line-content">          <span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="136"></td><td class="line-content">        <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="137"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="138"></td><td class="line-content">        <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">l</span>"&gt;</span></td></tr><tr><td class="line-number" value="139"></td><td class="line-content">          <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">lt</span>"&gt;</span>Fully Connected Layer<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="140"></td><td class="line-content">          <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">ld</span>"&gt;</span></td></tr><tr><td class="line-number" value="141"></td><td class="line-content">            Arguably the most important layer and building block of everything interesting. Declares a layer of neurons that perform weighted addition of all inputs (activations on layer below) and pass them through a nonlinearity. ReLU is the best activation to use if you know nothing about these networks. However, you have to be careful with keeping learning rates small because ReLU units can permanently die if a large gradient pushes them off your data manifold. In pratice, you may want to chain a few of these depending on how deep you want your deep learning to be ;) A good rule of thumb is you want just a few - maybe 1-3, unless you have really large datasets, in which case you shouldn't be using ConvNetJS anyway.</td></tr><tr><td class="line-number" value="142"></td><td class="line-content">          <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="143"></td><td class="line-content">          <span class="html-tag">&lt;pre <span class="html-attribute-name">class</span>="<span class="html-attribute-value">brush: js; toolbar: false;</span>"&gt;</span></td></tr><tr><td class="line-number" value="144"></td><td class="line-content">          // create layer of 10 linear neurons (no activation function by default)</td></tr><tr><td class="line-number" value="145"></td><td class="line-content">          {type:'fc', num_neurons:10}</td></tr><tr><td class="line-number" value="146"></td><td class="line-content">          // create layer of 10 neurons that use sigmoid activation function</td></tr><tr><td class="line-number" value="147"></td><td class="line-content">          {type:'fc', num_neurons:10, activation:'sigmoid'} // x-&gt;1/(1+e^(-x))</td></tr><tr><td class="line-number" value="148"></td><td class="line-content">          {type:'fc', num_neurons:10, activation:'tanh'} // x-&gt;tanh(x)</td></tr><tr><td class="line-number" value="149"></td><td class="line-content">          {type:'fc', num_neurons:10, activation:'relu'} // rectified linear units: x-&gt;max(0,x)</td></tr><tr><td class="line-number" value="150"></td><td class="line-content">          // maxout units: (x,y)-&gt;max(x,y). num_neurons must be divisible by 2.</td></tr><tr><td class="line-number" value="151"></td><td class="line-content">          // maxout "consumes" multiple filters for every output. Thus, this line</td></tr><tr><td class="line-number" value="152"></td><td class="line-content">          // will actually produce only 5 outputs in this layer. (group_size is 2)</td></tr><tr><td class="line-number" value="153"></td><td class="line-content">          // by default.</td></tr><tr><td class="line-number" value="154"></td><td class="line-content">          {type:'fc', num_neurons:10, activation:'maxout'} </td></tr><tr><td class="line-number" value="155"></td><td class="line-content">          // specify group size in maxout. num_neurons must be divisible by group_size.</td></tr><tr><td class="line-number" value="156"></td><td class="line-content">          // here, output will be 3 neurons only (3 = 12/4)</td></tr><tr><td class="line-number" value="157"></td><td class="line-content">          {type:'fc', num_neurons:12, group_size: 4, activation:'maxout'}</td></tr><tr><td class="line-number" value="158"></td><td class="line-content">          // dropout half the units (probability 0.5) in this layer during training, for regularization</td></tr><tr><td class="line-number" value="159"></td><td class="line-content">          {type:'fc', num_neurons:10, activation:'relu', drop_prob: 0.5}</td></tr><tr><td class="line-number" value="160"></td><td class="line-content">          <span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="161"></td><td class="line-content">        <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="162"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="163"></td><td class="line-content">        <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">l</span>"&gt;</span></td></tr><tr><td class="line-number" value="164"></td><td class="line-content">          <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">lt</span>"&gt;</span>Loss layers: Classifier Layers<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="165"></td><td class="line-content">          Use these if you are interested in predicting a set of discrete classes for your data. In softmax, the outputs are probabilities that sum to 1. An SVM is trained to only output scores, not probabilities. SVMs also use a bit better loss function that is more robust (a hinge loss), but its best to experiment a bit.</td></tr><tr><td class="line-number" value="166"></td><td class="line-content">          <span class="html-tag">&lt;pre <span class="html-attribute-name">class</span>="<span class="html-attribute-value">brush: js; toolbar: false;</span>"&gt;</span></td></tr><tr><td class="line-number" value="167"></td><td class="line-content">          layer_defs.push({type:'softmax', num_classes:2});</td></tr><tr><td class="line-number" value="168"></td><td class="line-content">          layer_defs.push({type:'svm', num_classes:2});</td></tr><tr><td class="line-number" value="169"></td><td class="line-content">          <span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="170"></td><td class="line-content">          When you are training a classifier layer, your classes must be numbers that begin at 0. For a binary problem, these would be class 0 and class 1. For K classes, the classes are 0..K-1.</td></tr><tr><td class="line-number" value="171"></td><td class="line-content">        <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="172"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="173"></td><td class="line-content">        <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">l</span>"&gt;</span></td></tr><tr><td class="line-number" value="174"></td><td class="line-content">          <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">lt</span>"&gt;</span>Loss layers: L2 Regression Layer<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="175"></td><td class="line-content">          <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">ld</span>"&gt;</span>Create a regression layer which takes a list of targets (arbitrary numbers, not necessarily a single discrete class label as in softmax/svm) and backprops the L2 Loss. With this, the outputs of your neural net can be arbitrary floating point numbers. In this example we are declaring that we will be predicting 3 numbers as outputs of the net.<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="176"></td><td class="line-content">          <span class="html-tag">&lt;pre <span class="html-attribute-name">class</span>="<span class="html-attribute-value">brush: js; toolbar: false;</span>"&gt;</span></td></tr><tr><td class="line-number" value="177"></td><td class="line-content">          // train 3 real-valued outputs</td></tr><tr><td class="line-number" value="178"></td><td class="line-content">          layer_defs.push({type:'regression', num_neurons: 3});</td></tr><tr><td class="line-number" value="179"></td><td class="line-content">          <span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="180"></td><td class="line-content">          When you are training a regression layer, you must pass the trainer a list of target values.</td></tr><tr><td class="line-number" value="181"></td><td class="line-content">        <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="182"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="183"></td><td class="line-content">        <span class="html-tag">&lt;h3&gt;</span>Layers for Convolutional Networks<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="184"></td><td class="line-content">        If you are training Convolutional Neural Networks (on images, presumably), these layers will be useful:</td></tr><tr><td class="line-number" value="185"></td><td class="line-content">        <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">l</span>"&gt;</span></td></tr><tr><td class="line-number" value="186"></td><td class="line-content">          <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">lt</span>"&gt;</span>Convolution Layer<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="187"></td><td class="line-content">          <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">ld</span>"&gt;</span></td></tr><tr><td class="line-number" value="188"></td><td class="line-content">            This layer is almost identical to fully connected layer shown above, but neurons are connected only locally to a few neurons in the layer below (not all of them), and their parameters are shared. The layer crucially takes three parameters: sx, filters, stride. These refer to the filter size, number of filters, and the stride at which they are applied in the input volume. All the other options passed to this layer (such as 'activation', 'drop_prob', 'tensor' work identically). You can also use an optional 'pad', to automatically pad the input by some amount of pixels with zeros. By default no padding is applied. The layer performs valid convolutions, so if the input volume has size W1xH1xD1, the output layer will have size W2xH2xD2, where </td></tr><tr><td class="line-number" value="189"></td><td class="line-content">            <span class="html-tag">&lt;pre&gt;</span></td></tr><tr><td class="line-number" value="190"></td><td class="line-content">            W2 = (W1 - sx + pad*2)/stride + 1</td></tr><tr><td class="line-number" value="191"></td><td class="line-content">            H2 = (H1 - sy + pad*2)/stride + 1</td></tr><tr><td class="line-number" value="192"></td><td class="line-content">            D2 = filters</td></tr><tr><td class="line-number" value="193"></td><td class="line-content">            <span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="194"></td><td class="line-content">            Every filter slides spatially along all x,y positions in the input volume computing a single activation map, a sheet of activations in the output volume. Note that he extent along the "depth" direction (the 3rd direction) is always the entire input depth, while the connectivity is restricted spatially. Lets see a few examples:</td></tr><tr><td class="line-number" value="195"></td><td class="line-content">          <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="196"></td><td class="line-content">          <span class="html-tag">&lt;pre <span class="html-attribute-name">class</span>="<span class="html-attribute-value">brush: js; toolbar: false;</span>"&gt;</span></td></tr><tr><td class="line-number" value="197"></td><td class="line-content">          // 8 5x5 filters will be convolved with the input</td></tr><tr><td class="line-number" value="198"></td><td class="line-content">          {type:'conv', sx:5, filters:8, stride:1, activation:'relu'}</td></tr><tr><td class="line-number" value="199"></td><td class="line-content">          // 10 3x3 filters will be convolved with the input. Padding of 1 applied automatically</td></tr><tr><td class="line-number" value="200"></td><td class="line-content">          {type:'conv', sx:3, pad:1, filters:10, stride:1, activation:'relu'}</td></tr><tr><td class="line-number" value="201"></td><td class="line-content">          // 10 3x4 filters will be applied (height of filter is different here)</td></tr><tr><td class="line-number" value="202"></td><td class="line-content">          {type:'conv', sx:3, sy: 4, pad:1, filters:10, stride:1, activation:'relu'}</td></tr><tr><td class="line-number" value="203"></td><td class="line-content">          // first layer of a Krizhevsky et al (2012) net. </td></tr><tr><td class="line-number" value="204"></td><td class="line-content">          // On input of size 227x227x3 gives volume 55x55x96</td></tr><tr><td class="line-number" value="205"></td><td class="line-content">          {type:'conv', sx:11, filters:96, stride:4, activation:'relu'}</td></tr><tr><td class="line-number" value="206"></td><td class="line-content">          <span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="207"></td><td class="line-content">        <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="208"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="209"></td><td class="line-content">        <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">l</span>"&gt;</span></td></tr><tr><td class="line-number" value="210"></td><td class="line-content">          <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">lt</span>"&gt;</span>Pooling Layer<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="211"></td><td class="line-content">          <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">ld</span>"&gt;</span>Performs max pooling. If size of input volume W1xH1xD1, then size of output volume is W2xH2xD2, where:</td></tr><tr><td class="line-number" value="212"></td><td class="line-content">          <span class="html-tag">&lt;pre&gt;</span></td></tr><tr><td class="line-number" value="213"></td><td class="line-content">            W2 = (W1 - sx + pad*2)/stride + 1</td></tr><tr><td class="line-number" value="214"></td><td class="line-content">            H2 = (H1 - sx + pad*2)/stride + 1</td></tr><tr><td class="line-number" value="215"></td><td class="line-content">            D2 = D1</td></tr><tr><td class="line-number" value="216"></td><td class="line-content">          <span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="217"></td><td class="line-content">          In particular note that the output depth is equal to input depth, because the max pooling happens in every slice of the input volume (activation maps) independently. The parameters passed to pooling layer are exactly same as to the convolutional layer (but of course, without 'activation'):</td></tr><tr><td class="line-number" value="218"></td><td class="line-content">          <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="219"></td><td class="line-content">          <span class="html-tag">&lt;pre <span class="html-attribute-name">class</span>="<span class="html-attribute-value">brush: js; toolbar: false;</span>"&gt;</span></td></tr><tr><td class="line-number" value="220"></td><td class="line-content">          // perform max pooling in 2x2 non-overlapping neighborhoods</td></tr><tr><td class="line-number" value="221"></td><td class="line-content">          {type:'pool', sx:2, stride:2}</td></tr><tr><td class="line-number" value="222"></td><td class="line-content">          <span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="223"></td><td class="line-content">        <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="224"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="225"></td><td class="line-content">        <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">l</span>"&gt;</span></td></tr><tr><td class="line-number" value="226"></td><td class="line-content">          <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">lt</span>"&gt;</span>Local Contrast Normalization Layer<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="227"></td><td class="line-content">          <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">ld</span>"&gt;</span>Local contrast normalization according to <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://code.google.com/p/cuda-convnet/wiki/LayerParams#Local_response_normalization_layer_(same_map)" rel="noreferrer noopener">https://code.google.com/p/cuda-convnet/wiki/LayerParams#Local_response_normalization_layer_(same_map)</a>"&gt;</span>this<span class="html-tag">&lt;/a&gt;</span> formula, but 1 is replaced with k. It creates local competition among neurons along depth, independently at every particular location in the input volume.<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="228"></td><td class="line-content">          <span class="html-tag">&lt;pre <span class="html-attribute-name">class</span>="<span class="html-attribute-value">brush: js; toolbar: false;</span>"&gt;</span></td></tr><tr><td class="line-number" value="229"></td><td class="line-content">          {type:'lrn', k:1, n:3, alpha:0.1, beta:0.75}</td></tr><tr><td class="line-number" value="230"></td><td class="line-content">          <span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="231"></td><td class="line-content">        <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="232"></td><td class="line-content">      <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="233"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="234"></td><td class="line-content">      <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">sec</span>"&gt;</span></td></tr><tr><td class="line-number" value="235"></td><td class="line-content">        <span class="html-tag">&lt;h3&gt;</span>Trainers<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="236"></td><td class="line-content">        <span class="html-tag">&lt;p&gt;</span></td></tr><tr><td class="line-number" value="237"></td><td class="line-content">        So, we've seen how to define a network. Lets see how we actually train one. We will need the Trainer class. The Trainer class takes a network and parameters, and then you pass it examples and the associated correct labels (class labels, or target values in regression). The trainer passes the examples through the network, sees the network predictions, and then adjusts the network weights to make the provided correct labels more likely for that particular input in the future. If you do this many, times for your entire dataset in turns, it will over time transform the network to map all inputs to correct outputs!</td></tr><tr><td class="line-number" value="238"></td><td class="line-content">        <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="239"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="240"></td><td class="line-content">        <span class="html-tag">&lt;pre <span class="html-attribute-name">class</span>="<span class="html-attribute-value">brush: js; toolbar: false;</span>"&gt;</span></td></tr><tr><td class="line-number" value="241"></td><td class="line-content">        // example SGD+Momentum trainer. Performs a weight update every 10 examples</td></tr><tr><td class="line-number" value="242"></td><td class="line-content">        var trainer = new convnetjs.Trainer(net, {method: 'sgd', learning_rate: 0.01, </td></tr><tr><td class="line-number" value="243"></td><td class="line-content">                                            l2_decay: 0.001, momentum: 0.9, batch_size: 10,</td></tr><tr><td class="line-number" value="244"></td><td class="line-content">                                            l1_decay: 0.001});</td></tr><tr><td class="line-number" value="245"></td><td class="line-content">        // example that uses adadelta. Reasonable for beginners.</td></tr><tr><td class="line-number" value="246"></td><td class="line-content">        var trainer = new convnetjs.Trainer(net, {method: 'adadelta', l2_decay: 0.001,</td></tr><tr><td class="line-number" value="247"></td><td class="line-content">                                            batch_size: 10});</td></tr><tr><td class="line-number" value="248"></td><td class="line-content">        // example adagrad.</td></tr><tr><td class="line-number" value="249"></td><td class="line-content">        var trainer = new convnetjs.Trainer(net, {method: 'adagrad', l2_decay: 0.001, </td></tr><tr><td class="line-number" value="250"></td><td class="line-content">                                            l1_decay: 0.001, batch_size: 10});</td></tr><tr><td class="line-number" value="251"></td><td class="line-content">        <span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="252"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="253"></td><td class="line-content">        <span class="html-tag">&lt;p&gt;</span></td></tr><tr><td class="line-number" value="254"></td><td class="line-content">        The three main options for a trainer are specified with 'method' and can be 'sgd'/'adagrad'/'adadelta'. The equations for these can be seen in this <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="http://www.matthewzeiler.com/pubs/googleTR2012/googleTR2012.pdf" rel="noreferrer noopener">http://www.matthewzeiler.com/pubs/googleTR2012/googleTR2012.pdf</a>"&gt;</span>paper<span class="html-tag">&lt;/a&gt;</span>. Also relevant, here is a <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/trainers.html" rel="noreferrer noopener">demo/trainers.html</a>"&gt;</span>ConvNetJS demo comparing these<span class="html-tag">&lt;/a&gt;</span> on MNIST. Here are some tips:</td></tr><tr><td class="line-number" value="255"></td><td class="line-content">        <span class="html-tag">&lt;ul&gt;</span></td></tr><tr><td class="line-number" value="256"></td><td class="line-content">          <span class="html-tag">&lt;li&gt;</span>If you are a newbie, I'd recommend using <span class="html-tag">&lt;b&gt;</span>Adadelta<span class="html-tag">&lt;/b&gt;</span> or then <span class="html-tag">&lt;b&gt;</span>Adagrad<span class="html-tag">&lt;/b&gt;</span>. They automatically adapt the learning rate and do it relatively reasonably.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="257"></td><td class="line-content">          <span class="html-tag">&lt;li&gt;</span>If you use <span class="html-tag">&lt;b&gt;</span>SGD<span class="html-tag">&lt;/b&gt;</span>, you almost always want to use a non-zero momentum. 0.9 is often used for momentum. You need to play with the learning rate a bit: if it's too high, your network will never converge at best, and will die catastrophically at worst, especially if you use ReLU activations. But if it's too low, the network will take very long to train. You need to monitor the cost of the training (as explained below)<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="258"></td><td class="line-content">          <span class="html-tag">&lt;li&gt;</span>You basically always want to use a non-zero <span class="html-tag">&lt;b&gt;</span>l2_decay<span class="html-tag">&lt;/b&gt;</span>. If it's too high, the network will be regularized very strongly. This might be a good idea if you have very few training data. If your training error is also very low (so your network is crushing the training set perfectly), you may want to increase this a bit to have better generalization. If your training error is very high (so the network is struggling to learn your data), you may want to try to decrease it.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="259"></td><td class="line-content">          <span class="html-tag">&lt;li&gt;</span>Use <span class="html-tag">&lt;b&gt;</span>l1_decay<span class="html-tag">&lt;/b&gt;</span> instead of l2_decay if you'd like your network to have sparse weights at the end, as l1 norm on weights is sparsity encouraging. If you have no idea what I'm talking about, don't touch l1_decay and leave it at 0 (default).<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="260"></td><td class="line-content">          <span class="html-tag">&lt;li&gt;</span>Usually you want to use <span class="html-tag">&lt;b&gt;</span>batch_size<span class="html-tag">&lt;/b&gt;</span> of 1. This basically controls how accurate the gradient steps of your network will be. If you let the network see 100 examples in a batch, it will be able to estimate a much better value for gradient before it actually takes the step. However, in practice a value of 1 (and having an appropriately small learning rate) is probably the best way to go.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="261"></td><td class="line-content">          <span class="html-tag">&lt;li&gt;</span>Q: I don't care about anything, just tell me what to use. A: okay, the 2nd example above (with 'adadelta') is probably good to try.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="262"></td><td class="line-content">        <span class="html-tag">&lt;/ul&gt;</span>      </td></tr><tr><td class="line-number" value="263"></td><td class="line-content">        <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="264"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="265"></td><td class="line-content">        <span class="html-tag">&lt;p&gt;</span></td></tr><tr><td class="line-number" value="266"></td><td class="line-content">          Lets see examples of actually training:</td></tr><tr><td class="line-number" value="267"></td><td class="line-content">        <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="268"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="269"></td><td class="line-content">        <span class="html-tag">&lt;pre <span class="html-attribute-name">class</span>="<span class="html-attribute-value">brush: js; toolbar: false;</span>"&gt;</span></td></tr><tr><td class="line-number" value="270"></td><td class="line-content">        // the trainer takes Vol() inputs.</td></tr><tr><td class="line-number" value="271"></td><td class="line-content">        var x = new convnetjs.Vol(1,1,d);</td></tr><tr><td class="line-number" value="272"></td><td class="line-content">        x.w[0] = 1; // set first feature to 1. example</td></tr><tr><td class="line-number" value="273"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="274"></td><td class="line-content">        // if your loss on top is</td></tr><tr><td class="line-number" value="275"></td><td class="line-content">        // layer_defs.push({type:'svm', num_classes: 5});</td></tr><tr><td class="line-number" value="276"></td><td class="line-content">        // use something like... (lets say x is class 3)</td></tr><tr><td class="line-number" value="277"></td><td class="line-content">        var stats = trainer.train(x, 3);</td></tr><tr><td class="line-number" value="278"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="279"></td><td class="line-content">        // if your loss on top is</td></tr><tr><td class="line-number" value="280"></td><td class="line-content">        // layer_defs.push({type:'regression', num_neurons: 1});</td></tr><tr><td class="line-number" value="281"></td><td class="line-content">        // use something like... (note the LIST!)</td></tr><tr><td class="line-number" value="282"></td><td class="line-content">        var stats = trainer.train(x, [0.7]);</td></tr><tr><td class="line-number" value="283"></td><td class="line-content">        // if your loss on top is</td></tr><tr><td class="line-number" value="284"></td><td class="line-content">        // layer_defs.push({type:'regression', num_neurons: 3});</td></tr><tr><td class="line-number" value="285"></td><td class="line-content">        // use something like</td></tr><tr><td class="line-number" value="286"></td><td class="line-content">        var stats = trainer.train(x, [0.7, 0.1, 0.3]);</td></tr><tr><td class="line-number" value="287"></td><td class="line-content">        <span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="288"></td><td class="line-content">        <span class="html-tag">&lt;p&gt;</span></td></tr><tr><td class="line-number" value="289"></td><td class="line-content">          The returned object stats contains the cost (which you want to be decrease over time as you train, that's good). It also returns other things such as the time to propagate forward and backwards. Here's a last, little more realistic example of a training loop:</td></tr><tr><td class="line-number" value="290"></td><td class="line-content">        <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="291"></td><td class="line-content">        </td></tr><tr><td class="line-number" value="292"></td><td class="line-content">        <span class="html-tag">&lt;pre <span class="html-attribute-name">class</span>="<span class="html-attribute-value">brush: js; toolbar: false;</span>"&gt;</span></td></tr><tr><td class="line-number" value="293"></td><td class="line-content">          var trainer = new convnetjs.SGDTrainer(net, {learning_rate:0.01, </td></tr><tr><td class="line-number" value="294"></td><td class="line-content">                            momentum:0.9, batch_size:16, l2_decay:0.001});</td></tr><tr><td class="line-number" value="295"></td><td class="line-content">          for(var i=0;i&amp;ltmy_data.length;i++) {</td></tr><tr><td class="line-number" value="296"></td><td class="line-content">            var x = new convnetjs.Vol(1,1,2,0.0); // a 1x1x2 volume initialized to 0's.</td></tr><tr><td class="line-number" value="297"></td><td class="line-content">            x.w[0] = my_data[i][0]; // Vol.w is just a list, it holds your data</td></tr><tr><td class="line-number" value="298"></td><td class="line-content">            x.w[1] = my_data[i][1];</td></tr><tr><td class="line-number" value="299"></td><td class="line-content">            trainer.train(x, my_labels[i]);</td></tr><tr><td class="line-number" value="300"></td><td class="line-content">          }</td></tr><tr><td class="line-number" value="301"></td><td class="line-content">        <span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="302"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="303"></td><td class="line-content">      <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="304"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="305"></td><td class="line-content"><span class="html-comment">&lt;!--</span></td></tr><tr><td class="line-number" value="306"></td><td class="line-content"><span class="html-comment">      &lt;div class="sec"&gt;</span></td></tr><tr><td class="line-number" value="307"></td><td class="line-content"><span class="html-comment">        &lt;h3&gt;Fully-Automatic Learning with MagicNet&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="308"></td><td class="line-content"><span class="html-comment">        &lt;p&gt;</span></td></tr><tr><td class="line-number" value="309"></td><td class="line-content"><span class="html-comment">        The MagicNet class performs fully-automatic prediction on your data. You don't have to worry about anything except providing your data and letting it train for a while. Internally, the MagicNet tries out many different types of networks, performs n-fold cross-validations of network hyper-parameters across folds of your data, and creates a final classifier ensemble by model averaging the best architectures.</span></td></tr><tr><td class="line-number" value="310"></td><td class="line-content"><span class="html-comment">        &lt;/p&gt;</span></td></tr><tr><td class="line-number" value="311"></td><td class="line-content"><span class="html-comment">        &lt;p&gt;</span></td></tr><tr><td class="line-number" value="312"></td><td class="line-content"><span class="html-comment">        In more detail, the MagicNet class first generates folds of the training data. Then, it samples a batch of candidate networks and trains and evaluates every one of them across the data folds. Once it has evaluated a batch of candidate networks, it will sample a new batch and evaluate those, forever. It keeps a record of the best performing networks and when you ask for a prediction, it will use the top few to do prediction on your data, and averages their predictions. Averaging is a powerful ensemble technique that almost always gives better results than a single network alone. Here's how you can set one up:</span></td></tr><tr><td class="line-number" value="313"></td><td class="line-content"><span class="html-comment">        &lt;/p&gt;</span></td></tr><tr><td class="line-number" value="314"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="315"></td><td class="line-content"><span class="html-comment">&lt;pre class="brush: js; toolbar: false;"&gt;</span></td></tr><tr><td class="line-number" value="316"></td><td class="line-content"><span class="html-comment">var opts = {}; // options struct</span></td></tr><tr><td class="line-number" value="317"></td><td class="line-content"><span class="html-comment">opts.train_ratio = 0.7; // what portion of data goes to train, in train/validation fold splits. Here, 70%</span></td></tr><tr><td class="line-number" value="318"></td><td class="line-content"><span class="html-comment">opts.num_folds = 1; // number of folds to evaluate per candidate</span></td></tr><tr><td class="line-number" value="319"></td><td class="line-content"><span class="html-comment">opts.num_candidates = 50; // number of candidates to evaluate in parallel</span></td></tr><tr><td class="line-number" value="320"></td><td class="line-content"><span class="html-comment">opts.num_epochs = 20; // number of epochs to make through data per fold</span></td></tr><tr><td class="line-number" value="321"></td><td class="line-content"><span class="html-comment">opts.ensemble_size = 20; // how many nets to average in the end for prediction? likely higher = better but slower</span></td></tr><tr><td class="line-number" value="322"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="323"></td><td class="line-content"><span class="html-comment">var magicNet = new convnetjs.MagicNet(train_data, train_labels, opts);</span></td></tr><tr><td class="line-number" value="324"></td><td class="line-content"><span class="html-comment">magicNet.onFinishBatch(finishedBatch); // example of setting callback for events</span></td></tr><tr><td class="line-number" value="325"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="326"></td><td class="line-content"><span class="html-comment">// start training MagicNet. Every call trains all candidates in current batch on one example</span></td></tr><tr><td class="line-number" value="327"></td><td class="line-content"><span class="html-comment">setInterval(function(){ magicNet.step(); }, 0});</span></td></tr><tr><td class="line-number" value="328"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="329"></td><td class="line-content"><span class="html-comment">function finishedBatch() {</span></td></tr><tr><td class="line-number" value="330"></td><td class="line-content"><span class="html-comment">  // prediction example. xout is Vol of scores</span></td></tr><tr><td class="line-number" value="331"></td><td class="line-content"><span class="html-comment">  // there is also predict_soft(), which returns the full score volume for all labels</span></td></tr><tr><td class="line-number" value="332"></td><td class="line-content"><span class="html-comment">  var predicted_label = magicNet.predict(some_test_vol);</span></td></tr><tr><td class="line-number" value="333"></td><td class="line-content"><span class="html-comment">}</span></td></tr><tr><td class="line-number" value="334"></td><td class="line-content"><span class="html-comment">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="335"></td><td class="line-content"><span class="html-comment">        &lt;p&gt;</span></td></tr><tr><td class="line-number" value="336"></td><td class="line-content"><span class="html-comment">          The MagicNet has a few more options that let you tweak the extent of the hyper-parameter settings that are used in sampling the candidate models. These are for now best inspected in the &lt;a href="https://github.com/karpathy/convnetjs/blob/master/src/convnet_magicnet.js"&gt;source code&lt;/a&gt; for the MagicNet. For example:</span></td></tr><tr><td class="line-number" value="337"></td><td class="line-content"><span class="html-comment">        &lt;/p&gt;</span></td></tr><tr><td class="line-number" value="338"></td><td class="line-content"><span class="html-comment">&lt;pre class="brush: js; toolbar: false;"&gt;</span></td></tr><tr><td class="line-number" value="339"></td><td class="line-content"><span class="html-comment">opts.neurons_min = 100; // set min and max number of neurons sampled per layer in magic net</span></td></tr><tr><td class="line-number" value="340"></td><td class="line-content"><span class="html-comment">opts.neurons_max = 300;</span></td></tr><tr><td class="line-number" value="341"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="342"></td><td class="line-content"><span class="html-comment">opts.l2_decay_min = 0; // would cause sampled models to have L2 weight decay from 10^0... 10^4</span></td></tr><tr><td class="line-number" value="343"></td><td class="line-content"><span class="html-comment">opts.l2_decay_max = 4; </span></td></tr><tr><td class="line-number" value="344"></td><td class="line-content"><span class="html-comment">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="345"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="346"></td><td class="line-content"><span class="html-comment">      &lt;/div&gt;</span></td></tr><tr><td class="line-number" value="347"></td><td class="line-content"><span class="html-comment">--&gt;</span></td></tr><tr><td class="line-number" value="348"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="349"></td><td class="line-content">      <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">sec</span>"&gt;</span></td></tr><tr><td class="line-number" value="350"></td><td class="line-content">        <span class="html-tag">&lt;h3&gt;</span>Saving and Loading Networks with JSON<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="351"></td><td class="line-content">        <span class="html-tag">&lt;p&gt;</span></td></tr><tr><td class="line-number" value="352"></td><td class="line-content">        Simply put, use the toJSON() and fromJSON() functions. For example to save and load a net:</td></tr><tr><td class="line-number" value="353"></td><td class="line-content">        <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="354"></td><td class="line-content"><span class="html-tag">&lt;pre <span class="html-attribute-name">class</span>="<span class="html-attribute-value">brush: js; toolbar: false;</span>"&gt;</span></td></tr><tr><td class="line-number" value="355"></td><td class="line-content">// network outputs all of its parameters into json object</td></tr><tr><td class="line-number" value="356"></td><td class="line-content">var json = net.toJSON();</td></tr><tr><td class="line-number" value="357"></td><td class="line-content">// the entire object is now simply string. You can save this somewhere</td></tr><tr><td class="line-number" value="358"></td><td class="line-content">var str = JSON.stringify(json);</td></tr><tr><td class="line-number" value="359"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="360"></td><td class="line-content">// later, to recreate the network:</td></tr><tr><td class="line-number" value="361"></td><td class="line-content">var json = JSON.parse(str); // creates json object out of a string</td></tr><tr><td class="line-number" value="362"></td><td class="line-content">var net2 = new convnetjs.Net(); // create an empty network</td></tr><tr><td class="line-number" value="363"></td><td class="line-content">net2.fromJSON(json); // load all parameters from JSON</td></tr><tr><td class="line-number" value="364"></td><td class="line-content"><span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="365"></td><td class="line-content">        <span class="html-tag">&lt;p&gt;</span></td></tr><tr><td class="line-number" value="366"></td><td class="line-content">        After executing the last line, net2 should be an exact duplicate of the original net.</td></tr><tr><td class="line-number" value="367"></td><td class="line-content">        <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="368"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="369"></td><td class="line-content">      <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="370"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="371"></td><td class="line-content">      <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">sec</span>"&gt;</span></td></tr><tr><td class="line-number" value="372"></td><td class="line-content">        <span class="html-tag">&lt;h3&gt;</span>Utilities and Visualizations<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="373"></td><td class="line-content">        <span class="html-tag">&lt;p&gt;</span></td></tr><tr><td class="line-number" value="374"></td><td class="line-content">        See github repo for modules (vis and util inside build/) that do small useful things, like plot graphs and so on. See demos for examples on how to use this functionality for now.</td></tr><tr><td class="line-number" value="375"></td><td class="line-content">        <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="376"></td><td class="line-content">      <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="377"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="378"></td><td class="line-content">      <span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">sec</span>"&gt;</span></td></tr><tr><td class="line-number" value="379"></td><td class="line-content">        <span class="html-tag">&lt;h3&gt;</span>Reinforcement Learning<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="380"></td><td class="line-content">        <span class="html-tag">&lt;p&gt;</span></td></tr><tr><td class="line-number" value="381"></td><td class="line-content">        There is a module available to do Reinforcement Learning using <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="http://arxiv.org/abs/1312.5602" rel="noreferrer noopener">http://arxiv.org/abs/1312.5602</a>"&gt;</span>Deep Q Learning<span class="html-tag">&lt;/a&gt;</span>. This allows you to create a deeqlearn.Brain() instance that takes states and rewards over time and produces a discrete action. Over time, the brain automagically adjusts its weights to perform actions that maximize the expected, time-discounted reward.</td></tr><tr><td class="line-number" value="382"></td><td class="line-content">        <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="383"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="384"></td><td class="line-content">        <span class="html-tag">&lt;p&gt;</span></td></tr><tr><td class="line-number" value="385"></td><td class="line-content">          For example, lets train an agent that observes 3-dimensional states and is asked to do one of two actions. Lets reward the agent only for action 0 for sake of very simple example:</td></tr><tr><td class="line-number" value="386"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="387"></td><td class="line-content"><span class="html-tag">&lt;pre <span class="html-attribute-name">class</span>="<span class="html-attribute-value">brush: js; toolbar: false;</span>"&gt;</span></td></tr><tr><td class="line-number" value="388"></td><td class="line-content">var brain = new deepqlearn.Brain(3, 2); // 3 inputs, 2 possible outputs (0,1)</td></tr><tr><td class="line-number" value="389"></td><td class="line-content">var state = [Math.random(), Math.random(), Math.random()];</td></tr><tr><td class="line-number" value="390"></td><td class="line-content">for(var k=0;k&amp;lt10000;k++) {</td></tr><tr><td class="line-number" value="391"></td><td class="line-content">    var action = brain.forward(state); // returns index of chosen action</td></tr><tr><td class="line-number" value="392"></td><td class="line-content">    var reward = action === 0 ? 1.0 : 0.0;</td></tr><tr><td class="line-number" value="393"></td><td class="line-content">    brain.backward([reward]); // &amp;lt-- learning magic happens here</td></tr><tr><td class="line-number" value="394"></td><td class="line-content">    state[Math.floor(Math.random()*3)] += Math.random()*2-0.5;</td></tr><tr><td class="line-number" value="395"></td><td class="line-content">}</td></tr><tr><td class="line-number" value="396"></td><td class="line-content">brain.epsilon_test_time = 0.0; // don't make any more random choices</td></tr><tr><td class="line-number" value="397"></td><td class="line-content">brain.learning = false;</td></tr><tr><td class="line-number" value="398"></td><td class="line-content">// get an optimal action from the learned policy</td></tr><tr><td class="line-number" value="399"></td><td class="line-content">var action = brain.forward(array_with_num_inputs_numbers);</td></tr><tr><td class="line-number" value="400"></td><td class="line-content"><span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="401"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="402"></td><td class="line-content">        Of course, there are many possible options you can set. have a look at the reinfocement learning demo rldemo.html inside demo/ folder, or see the <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html" rel="noreferrer noopener">demo/rldemo.html</a>"&gt;</span>Reinforcement Learning demo<span class="html-tag">&lt;/a&gt;</span> for more documentation.</td></tr><tr><td class="line-number" value="403"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="404"></td><td class="line-content">        <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="405"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="406"></td><td class="line-content">        <span class="html-tag">&lt;p&gt;</span></td></tr><tr><td class="line-number" value="407"></td><td class="line-content">          For Reinforcement Learning you might also be interested in my other projects <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="http://cs.stanford.edu/people/karpathy/reinforcejs/" rel="noreferrer noopener">http://cs.stanford.edu/people/karpathy/reinforcejs/</a>"&gt;</span>reinforcejs<span class="html-tag">&lt;/a&gt;</span>.</td></tr><tr><td class="line-number" value="408"></td><td class="line-content">        <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="409"></td><td class="line-content">      <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="410"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="411"></td><td class="line-content">      <span class="html-tag">&lt;div <span class="html-attribute-name">id</span>="<span class="html-attribute-value">footer</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">sec</span>"&gt;</span></td></tr><tr><td class="line-number" value="412"></td><td class="line-content">      <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="413"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="414"></td><td class="line-content">    <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="415"></td><td class="line-content">  <span class="html-tag">&lt;/body&gt;</span></td></tr><tr><td class="line-number" value="416"></td><td class="line-content"><span class="html-tag">&lt;/html&gt;</span></td></tr><tr><td class="line-number" value="417"></td><td class="line-content"><span class="html-end-of-file"></span></td></tr></tbody></table></body></html>